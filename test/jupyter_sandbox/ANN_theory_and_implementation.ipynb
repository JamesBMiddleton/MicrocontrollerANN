{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc78120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d1c10",
   "metadata": {},
   "source": [
    "## Simple perceptron w/sklearn API + Iris classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15392e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] # only petal length and width\n",
    "y = (iris.target == 0).astype(int)  # make binary \"is it a setosa?\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b1c352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc4ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(perceptron.score(X_test, y_test)) # given petal length of 2 and width of 0.5, is it a setosa?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcf22b",
   "metadata": {},
   "source": [
    "## Simple perceptron from scratch w/Iris classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863820e",
   "metadata": {},
   "source": [
    "A single neuron/node with:\n",
    "- 2 inputs (petal length and width) and 2 input weights\n",
    "- 1 bias input (always inputs 1) and 1 bias weight\n",
    "- 1 binary output (1 == \"is setosa\", 0 == \"is not setosa\")\n",
    "\n",
    "Learning process:\n",
    "- For each input instance in training set:\n",
    "    - multiply each input feature (petal length and width) by its weight, and multiply the bias by its weight\n",
    "    - Sum the results\n",
    "    - If greater than or equal to 0, output 1, else output 0\n",
    "    - Calculate error by minusing the output from the target output. \n",
    "    - For each weight:\n",
    "        - Add the ((error * learning rate) * input) to the weight\n",
    "        - e.g. if the weight was 0.5, the input was -0.7, the output was 1 and the target output was 0, that's an error of -1, 0.05 * -1 * -0.7 = 0.035, so new weight is 0.535. If you got the same input again you've amplified the negative input which will result in a sum of weights * inputs closer to being less than 0, resulting in an output of 0, the target.\n",
    "        - e.g. if the weight was 0.5, the input was 0.7, the output 1 and the target output was 0, that's error of -1, 0.05 * -1 * 0.7 = -0.035, so the new weight is 0.465. If you got the same input again, you've supressed the positive input which will result in a sum of weights * inputs closer to being less than 0, resulting in an output of 0, the target.\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7f080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPerceptron:\n",
    "    def __init__(self):   \n",
    "        self.input_weights = [0.5, 0.5]\n",
    "        self.bias_weight = 0.5\n",
    "        self.learning_rate = 0.05\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for i in range(0, X.shape[0]):\n",
    "            output = self.predict(X[i, :])\n",
    "            error = y[i] - output\n",
    "            for j in range(0, len(self.input_weights)):\n",
    "                self.input_weights[j] = self.input_weights[j] + ((self.learning_rate * error) * X[i, j])\n",
    "            self.bias_weight = self.bias_weight + ((self.learning_rate * error) * 1)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        product = 0\n",
    "        for input_val, weight in zip(x, self.input_weights):\n",
    "            product += input_val * weight\n",
    "        product += 1 * self.bias_weight\n",
    "        return int(product >= 0) # simple heaviside step function\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        error = y.shape[0]\n",
    "        for i in range(0, X.shape[0]):\n",
    "            output = self.predict(X[i, :])\n",
    "            error -= abs(y[i] - output)\n",
    "        return f\"{error}/{y.shape[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce6ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5]\n",
      "14/38\n",
      "[-0.21500000000000002, 0.27]\n",
      "36/38\n"
     ]
    }
   ],
   "source": [
    "model = MyPerceptron()\n",
    "print(model.input_weights)\n",
    "print(model.score(X_test,y_test))\n",
    "model.fit(X_train, y_train)\n",
    "print(model.input_weights)\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597a7d0",
   "metadata": {},
   "source": [
    "## Simple perceptron continous output using backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a0d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + math.exp(-z))\n",
    "\n",
    "def half_mse(a, y):\n",
    "    return 0.5 * ((a - y)**2)   # half MSE is nicer derivative than MSE\n",
    "\n",
    "\n",
    "class BackPropagatingPerceptron:\n",
    "    def __init__(self):\n",
    "        self.a_out = []   # output after sigmoid - is a matrix because storing output from multiple input instances\n",
    "        #self.z_out = []   # doesn't need storing for backprop\n",
    "        self.w_out = [0.5, 0.5]\n",
    "        self.b_out = 0.5\n",
    "        \n",
    "        self.l_rate = 0.5\n",
    "    \n",
    "    def forward_pass(self, X, y):\n",
    "        cost_out = []\n",
    "        for i in range(0, X.shape[0]):\n",
    "            z_out = 0\n",
    "            for j in range(0, len(self.w_out)):\n",
    "                z_out += self.w_out[j] * X[i, j]\n",
    "            z_out += self.b_out\n",
    "            squished = sigmoid(z_out)\n",
    "            self.a_out.append(squished) # matrix cus for hidden layers it'd be multiple outputs per input instance\n",
    "            cost = half_mse(squished, y[i])\n",
    "            cost_out.append(cost)\n",
    "        return sum(cost_out)\n",
    "    \n",
    "    def backwards_pass(self, X, y):\n",
    "        w_delta_out = [[],[]] # 1 gradient per weight per input instance\n",
    "        b_delta_out = [] # 1 gradient per input instance\n",
    "        for i in range(0, X.shape[0]): # i = instance\n",
    "            for j in range(0, len(self.w_out)): # j = weight\n",
    "                print(-(y[i] - self.a_out[i]))\n",
    "                w_delta_out[j].append((-(y[i] - self.a_out[i])) * (self.a_out[i]*(1-self.a_out[i])) * X[i, j])  \n",
    "            b_delta_out.append((-(y[i] - self.a_out[i])) * (self.a_out[i]*(1-self.a_out[i])) * 1)\n",
    "        \n",
    "        for i in range(0, len(w_delta_out)):\n",
    "            self.w_out[i] = self.w_out[i] - (self.l_rate * (sum(w_delta_out[i]) / len(w_delta_out[i])))\n",
    "        self.b_out = self.b_out - (self.l_rate * (sum(b_delta_out) / len(b_delta_out)))\n",
    "        \n",
    "        # why are my gradient exploding after a while? read le book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12df92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X = diabetes.data[:, (0,3)]\n",
    "y = diabetes.target\n",
    "\n",
    "scaler = MinMaxScaler()  # because output is sigmoid\n",
    "y = scaler.fit_transform(y.reshape(-1, 1))\n",
    "y = y.reshape(-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3292e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.767620345732574\n",
      "0.4389289184383177\n",
      "0.4389289184383177\n",
      "0.31473651020368476\n",
      "0.31473651020368476\n",
      "-0.05900281355170456\n",
      "-0.05900281355170456\n",
      "-0.23198053141744535\n",
      "-0.23198053141744535\n",
      "0.39404613787438714\n",
      "0.39404613787438714\n",
      "-0.3516356935067194\n",
      "-0.3516356935067194\n",
      "0.595888832679675\n",
      "0.595888832679675\n",
      "-0.04795932628223265\n",
      "-0.04795932628223265\n",
      "-0.09915727006984709\n",
      "-0.09915727006984709\n",
      "0.40812430868190974\n",
      "0.40812430868190974\n",
      "0.09002763743350373\n",
      "0.09002763743350373\n",
      "0.21678814889669518\n",
      "0.21678814889669518\n",
      "0.11075988596690822\n",
      "0.11075988596690822\n",
      "0.15424587031388737\n",
      "0.15424587031388737\n",
      "0.025209863186482995\n",
      "0.025209863186482995\n",
      "0.4752454480784013\n",
      "0.4752454480784013\n",
      "0.21569176441407872\n",
      "0.21569176441407872\n",
      "0.025427772686548833\n",
      "0.025427772686548833\n",
      "0.11600190931851928\n",
      "0.11600190931851928\n",
      "0.552213328626229\n",
      "0.552213328626229\n",
      "0.39908609236227865\n",
      "0.39908609236227865\n",
      "0.18827392670268084\n",
      "0.18827392670268084\n",
      "0.10958918430553699\n",
      "0.10958918430553699\n",
      "0.3689402715505416\n",
      "0.3689402715505416\n",
      "0.6213345562373987\n",
      "0.6213345562373987\n",
      "0.14453153728215906\n",
      "0.14453153728215906\n",
      "0.33232038664105285\n",
      "0.33232038664105285\n",
      "0.46552470735159057\n",
      "0.46552470735159057\n",
      "-0.23000868586866863\n",
      "-0.23000868586866863\n",
      "-0.11474892717953455\n",
      "-0.11474892717953455\n",
      "-0.17278374027099186\n",
      "-0.17278374027099186\n",
      "0.33532709584640824\n",
      "0.33532709584640824\n",
      "0.22660989317370506\n",
      "0.22660989317370506\n",
      "0.05461618938886681\n",
      "0.05461618938886681\n",
      "0.4871502378190777\n",
      "0.4871502378190777\n",
      "0.25451843814101993\n",
      "0.25451843814101993\n",
      "0.33255915336782094\n",
      "0.33255915336782094\n",
      "0.4839219868197604\n",
      "0.4839219868197604\n",
      "0.637302192277196\n",
      "0.637302192277196\n",
      "0.06504443522371328\n",
      "0.06504443522371328\n",
      "0.06560777834860698\n",
      "0.06560777834860698\n",
      "0.013167105418563918\n",
      "0.013167105418563918\n",
      "0.3749402226878527\n",
      "0.3749402226878527\n",
      "0.16102654556224583\n",
      "0.16102654556224583\n",
      "0.19372361353627665\n",
      "0.19372361353627665\n",
      "0.22961745595143407\n",
      "0.22961745595143407\n",
      "0.16759806707711394\n",
      "0.16759806707711394\n",
      "0.48199657784945954\n",
      "0.48199657784945954\n",
      "0.3460496224481243\n",
      "0.3460496224481243\n",
      "0.4146492836241482\n",
      "0.4146492836241482\n",
      "-0.1931727466167601\n",
      "-0.1931727466167601\n",
      "0.5949013444714604\n",
      "0.5949013444714604\n",
      "0.06247300461826377\n",
      "0.06247300461826377\n",
      "0.21492694185676015\n",
      "0.21492694185676015\n",
      "0.007169008566224044\n",
      "0.007169008566224044\n",
      "0.4932036025797983\n",
      "0.4932036025797983\n",
      "0.17978016883047243\n",
      "0.17978016883047243\n",
      "0.29180555351843424\n",
      "0.29180555351843424\n",
      "0.3737967689631258\n",
      "0.3737967689631258\n",
      "0.27509119502911267\n",
      "0.27509119502911267\n",
      "0.2296598150195377\n",
      "0.2296598150195377\n",
      "0.2418147950845968\n",
      "0.2418147950845968\n",
      "-0.02326543984250129\n",
      "-0.02326543984250129\n",
      "0.1325810867836169\n",
      "0.1325810867836169\n",
      "0.39482405880659366\n",
      "0.39482405880659366\n",
      "0.054910701173262355\n",
      "0.054910701173262355\n",
      "0.1744406422312107\n",
      "0.1744406422312107\n",
      "0.04570428808344196\n",
      "0.04570428808344196\n",
      "0.28820504855176354\n",
      "0.28820504855176354\n",
      "-0.20120041635999592\n",
      "-0.20120041635999592\n",
      "0.5220036769962473\n",
      "0.5220036769962473\n",
      "-0.15237908941478207\n",
      "-0.15237908941478207\n",
      "0.2864054411082055\n",
      "0.2864054411082055\n",
      "-0.1426866723579565\n",
      "-0.1426866723579565\n",
      "-0.10517619457613314\n",
      "-0.10517619457613314\n",
      "0.40802119963337274\n",
      "0.40802119963337274\n",
      "0.3686039887507711\n",
      "0.3686039887507711\n",
      "0.30807089791135306\n",
      "0.30807089791135306\n",
      "0.5113219870115597\n",
      "0.5113219870115597\n",
      "0.6010642720898973\n",
      "0.6010642720898973\n",
      "0.3728347533224316\n",
      "0.3728347533224316\n",
      "0.21096822623449096\n",
      "0.21096822623449096\n",
      "0.37424002444365506\n",
      "0.37424002444365506\n",
      "0.1887442778149762\n",
      "0.1887442778149762\n",
      "0.4830365346160195\n",
      "0.4830365346160195\n",
      "-0.18829711857799775\n",
      "-0.18829711857799775\n",
      "0.26040250302377466\n",
      "0.26040250302377466\n",
      "0.22785744447280915\n",
      "0.22785744447280915\n",
      "-0.10105703373353842\n",
      "-0.10105703373353842\n",
      "0.22259879168181418\n",
      "0.22259879168181418\n",
      "0.04567237806455249\n",
      "0.04567237806455249\n",
      "0.3206057073830182\n",
      "0.3206057073830182\n",
      "0.6582437433752306\n",
      "0.6582437433752306\n",
      "-0.16861458611247243\n",
      "-0.16861458611247243\n",
      "-0.3429054829400505\n",
      "-0.3429054829400505\n",
      "0.32570336965788765\n",
      "0.32570336965788765\n",
      "0.4609670474325467\n",
      "0.4609670474325467\n",
      "0.23429353784740486\n",
      "0.23429353784740486\n",
      "0.608969328874196\n",
      "0.608969328874196\n",
      "0.6439609498810634\n",
      "0.6439609498810634\n",
      "-0.0779439182113072\n",
      "-0.0779439182113072\n",
      "-0.05875237811985312\n",
      "-0.05875237811985312\n",
      "0.16508209791779893\n",
      "0.16508209791779893\n",
      "0.3228830669601726\n",
      "0.3228830669601726\n",
      "0.6244060736518388\n",
      "0.6244060736518388\n",
      "-0.01157669906217107\n",
      "-0.01157669906217107\n",
      "0.29885917074536517\n",
      "0.29885917074536517\n",
      "0.6628426197089269\n",
      "0.6628426197089269\n",
      "0.17819564353595718\n",
      "0.17819564353595718\n",
      "0.08330231972020063\n",
      "0.08330231972020063\n",
      "0.03277135042839174\n",
      "0.03277135042839174\n",
      "0.20605309345993267\n",
      "0.20605309345993267\n",
      "0.16727275389700086\n",
      "0.16727275389700086\n",
      "0.0018530699925382033\n",
      "0.0018530699925382033\n",
      "0.3139188145170785\n",
      "0.3139188145170785\n",
      "0.23611587287206748\n",
      "0.23611587287206748\n",
      "0.08329438564605246\n",
      "0.08329438564605246\n",
      "0.439576049168354\n",
      "0.439576049168354\n",
      "0.08061704943870474\n",
      "0.08061704943870474\n",
      "0.03692765845396334\n",
      "0.03692765845396334\n",
      "0.40881074129352285\n",
      "0.40881074129352285\n",
      "0.17783337157424683\n",
      "0.17783337157424683\n",
      "0.2864466258882197\n",
      "0.2864466258882197\n",
      "0.2898569708363265\n",
      "0.2898569708363265\n",
      "0.12607445456647848\n",
      "0.12607445456647848\n",
      "-0.12369042088087123\n",
      "-0.12369042088087123\n",
      "0.2817269459259821\n",
      "0.2817269459259821\n",
      "0.5946333238268837\n",
      "0.5946333238268837\n",
      "-0.05314416168849645\n",
      "-0.05314416168849645\n",
      "0.25124651004055165\n",
      "0.25124651004055165\n",
      "0.09915367702675604\n",
      "0.09915367702675604\n",
      "-0.1760350908393653\n",
      "-0.1760350908393653\n",
      "0.10108582485452033\n",
      "0.10108582485452033\n",
      "0.04296644926685267\n",
      "0.04296644926685267\n",
      "0.2567075784804938\n",
      "0.2567075784804938\n",
      "0.20143274329294186\n",
      "0.20143274329294186\n",
      "0.26481665103452506\n",
      "0.26481665103452506\n",
      "-0.08565012174504605\n",
      "-0.08565012174504605\n",
      "0.08073742747753804\n",
      "0.08073742747753804\n",
      "0.3337537514158873\n",
      "0.3337537514158873\n",
      "0.18940560656110872\n",
      "0.18940560656110872\n",
      "0.4645292971430154\n",
      "0.4645292971430154\n",
      "0.5420705546536937\n",
      "0.5420705546536937\n",
      "0.004392549603035145\n",
      "0.004392549603035145\n",
      "-0.16087553945165878\n",
      "-0.16087553945165878\n",
      "-0.11436323380406432\n",
      "-0.11436323380406432\n",
      "-0.2678478019370363\n",
      "-0.2678478019370363\n",
      "0.15036346660650607\n",
      "0.15036346660650607\n",
      "0.06717501656011027\n",
      "0.06717501656011027\n",
      "0.2712112612578006\n",
      "0.2712112612578006\n",
      "-0.3191428136138724\n",
      "-0.3191428136138724\n",
      "0.3435540005242389\n",
      "0.3435540005242389\n",
      "-0.16348169996612677\n",
      "-0.16348169996612677\n",
      "0.5475454052156932\n",
      "0.5475454052156932\n",
      "0.01589385708335811\n",
      "0.01589385708335811\n",
      "-0.09488399040083034\n",
      "-0.09488399040083034\n",
      "0.18780013041633659\n",
      "0.18780013041633659\n",
      "0.08506736085144628\n",
      "0.08506736085144628\n",
      "0.053920395760481465\n",
      "0.053920395760481465\n",
      "0.22758032252390803\n",
      "0.22758032252390803\n",
      "0.2089798680861581\n",
      "0.2089798680861581\n",
      "0.48856736798433426\n",
      "0.48856736798433426\n",
      "0.14880978024916575\n",
      "0.14880978024916575\n",
      "0.22561275644358014\n",
      "0.22561275644358014\n",
      "0.3287038340852432\n",
      "0.3287038340852432\n",
      "-0.20031619661227565\n",
      "-0.20031619661227565\n",
      "0.12103980798667363\n",
      "0.12103980798667363\n",
      "0.7037202761405088\n",
      "0.7037202761405088\n",
      "0.09383289007889273\n",
      "0.09383289007889273\n",
      "0.452293588440601\n",
      "0.452293588440601\n",
      "0.4719770508849324\n",
      "0.4719770508849324\n",
      "0.3653792422610369\n",
      "0.3653792422610369\n",
      "0.34388479349495965\n",
      "0.34388479349495965\n",
      "0.43816714816039665\n",
      "0.43816714816039665\n",
      "0.27121978535108304\n",
      "0.27121978535108304\n",
      "0.09474973940324394\n",
      "0.09474973940324394\n",
      "0.13225930520734985\n",
      "0.13225930520734985\n",
      "0.46806653638993606\n",
      "0.46806653638993606\n",
      "0.05889253979403386\n",
      "0.05889253979403386\n",
      "-0.07791668820232323\n",
      "-0.07791668820232323\n",
      "0.5759024729320934\n",
      "0.5759024729320934\n",
      "0.2988609018054669\n",
      "0.2988609018054669\n",
      "0.3099540269522033\n",
      "0.3099540269522033\n",
      "0.11375962577043541\n",
      "0.11375962577043541\n",
      "-0.24246322327183017\n",
      "-0.24246322327183017\n",
      "0.16076341515078918\n",
      "0.16076341515078918\n",
      "0.008293010854801275\n",
      "0.008293010854801275\n",
      "0.2788592475001519\n",
      "0.2788592475001519\n",
      "0.007918987028896929\n",
      "0.007918987028896929\n",
      "-0.0034584756227677427\n",
      "-0.0034584756227677427\n",
      "0.32118814164576875\n",
      "0.32118814164576875\n",
      "0.7024503691627878\n",
      "0.7024503691627878\n",
      "0.12215015304895677\n",
      "0.12215015304895677\n",
      "-0.02859578444408961\n",
      "-0.02859578444408961\n",
      "0.6820847080261944\n",
      "0.6820847080261944\n",
      "0.4772279543938445\n",
      "0.4772279543938445\n",
      "0.2860456396039791\n",
      "0.2860456396039791\n",
      "0.21181934575949624\n",
      "0.21181934575949624\n",
      "0.1660820975923587\n",
      "0.1660820975923587\n",
      "-0.13447401586355912\n",
      "-0.13447401586355912\n",
      "0.3390082773508022\n",
      "0.3390082773508022\n",
      "-0.23082848344479334\n",
      "-0.23082848344479334\n",
      "0.1720911645349527\n",
      "0.1720911645349527\n",
      "0.5080631839052971\n",
      "0.5080631839052971\n",
      "0.0871281274061727\n",
      "0.0871281274061727\n",
      "0.11432721476835273\n",
      "0.11432721476835273\n",
      "0.347790598892605\n",
      "0.347790598892605\n",
      "0.14238885764615627\n",
      "0.14238885764615627\n",
      "0.186337616644837\n",
      "0.186337616644837\n",
      "0.37426133759759156\n",
      "0.37426133759759156\n",
      "0.12090581886173613\n",
      "0.12090581886173613\n",
      "0.6017297988929282\n",
      "0.6017297988929282\n",
      "-0.16713967433860233\n",
      "-0.16713967433860233\n",
      "0.3713404113282241\n",
      "0.3713404113282241\n",
      "0.44135465455382544\n",
      "0.44135465455382544\n",
      "0.166534626748589\n",
      "0.166534626748589\n",
      "0.4486652805121178\n",
      "0.4486652805121178\n",
      "0.4358307597501007\n",
      "0.4358307597501007\n",
      "0.2916153636276328\n",
      "0.2916153636276328\n",
      "-0.09945013846893502\n",
      "-0.09945013846893502\n",
      "0.24576656938689267\n",
      "0.24576656938689267\n",
      "0.11126078261600642\n",
      "0.11126078261600642\n",
      "-0.020376763849842883\n",
      "-0.020376763849842883\n",
      "0.4238632300620026\n",
      "0.4238632300620026\n",
      "0.17654127318359192\n",
      "0.17654127318359192\n",
      "0.4186041132471822\n",
      "0.4186041132471822\n",
      "0.38238631272888535\n",
      "0.38238631272888535\n",
      "0.6291959271030445\n",
      "0.6291959271030445\n",
      "0.31164456936495527\n",
      "0.31164456936495527\n",
      "0.17601613957649132\n",
      "0.17601613957649132\n",
      "-0.11362221824107221\n",
      "-0.11362221824107221\n",
      "0.1807972559516543\n",
      "0.1807972559516543\n",
      "0.18076740846288786\n",
      "0.18076740846288786\n",
      "0.13564143153515318\n",
      "0.13564143153515318\n",
      "0.25297021348343945\n",
      "0.25297021348343945\n",
      "0.14740921005643381\n",
      "0.14740921005643381\n",
      "0.0579657859982623\n",
      "0.0579657859982623\n",
      "0.2744121878437849\n",
      "0.2744121878437849\n",
      "0.4876837690102332\n",
      "0.4876837690102332\n",
      "-0.008641942430250182\n",
      "-0.008641942430250182\n",
      "0.3428673450987813\n",
      "0.3428673450987813\n",
      "0.29550643046535713\n",
      "0.29550643046535713\n",
      "0.33647902910010147\n",
      "0.33647902910010147\n",
      "0.4267906938845289\n",
      "0.4267906938845289\n",
      "0.3736686379335277\n",
      "0.3736686379335277\n",
      "0.5322012911036118\n",
      "0.5322012911036118\n",
      "0.02033674927683851\n",
      "0.02033674927683851\n",
      "0.35259816369333974\n",
      "0.35259816369333974\n",
      "0.23239669743952118\n",
      "0.23239669743952118\n",
      "-0.36868418432874894\n",
      "-0.36868418432874894\n",
      "0.06468696039249255\n",
      "0.06468696039249255\n",
      "0.5619772611566523\n",
      "0.5619772611566523\n",
      "-0.09542369239841231\n",
      "-0.09542369239841231\n",
      "0.3836071319901149\n",
      "0.3836071319901149\n",
      "0.5016874253511467\n",
      "0.5016874253511467\n",
      "0.6896419103891928\n",
      "0.6896419103891928\n",
      "0.1849059770477094\n",
      "0.1849059770477094\n",
      "0.3497940174487323\n",
      "0.3497940174487323\n",
      "0.35151047209013864\n",
      "0.35151047209013864\n",
      "0.1186938394894812\n",
      "0.1186938394894812\n",
      "0.23091613573862407\n",
      "0.23091613573862407\n",
      "0.19038480529627116\n",
      "0.19038480529627116\n",
      "0.4783530223291253\n",
      "0.4783530223291253\n",
      "0.31486668117837663\n",
      "0.31486668117837663\n",
      "0.4819893025978199\n",
      "0.4819893025978199\n",
      "0.3937431663790982\n",
      "0.3937431663790982\n",
      "-0.18943896078270625\n",
      "-0.18943896078270625\n",
      "-0.03717037263513345\n",
      "-0.03717037263513345\n",
      "0.6578101270851393\n",
      "0.6578101270851393\n",
      "-0.3017669314868916\n",
      "-0.3017669314868916\n",
      "0.21752568720006726\n",
      "0.21752568720006726\n",
      "0.5755570025399575\n",
      "0.5755570025399575\n",
      "-0.1134343942745718\n",
      "-0.1134343942745718\n",
      "0.31629656771598663\n",
      "0.31629656771598663\n",
      "0.04414894581331896\n",
      "0.04414894581331896\n",
      "0.11647853504953792\n",
      "0.11647853504953792\n",
      "-0.09327316162236499\n",
      "-0.09327316162236499\n",
      "0.2884376833838227\n",
      "0.2884376833838227\n",
      "0.31310973872240266\n",
      "0.31310973872240266\n",
      "0.35386008449610623\n",
      "0.35386008449610623\n",
      "0.3622023091086709\n",
      "0.3622023091086709\n",
      "0.15084375186677745\n",
      "0.15084375186677745\n",
      "0.24464327636875988\n",
      "0.24464327636875988\n",
      "0.12867477414581507\n",
      "0.12867477414581507\n",
      "0.17595052985890902\n",
      "0.17595052985890902\n",
      "-0.2365502171023769\n",
      "-0.2365502171023769\n",
      "0.4027498988741299\n",
      "0.4027498988741299\n",
      "-0.14829997913235127\n",
      "-0.14829997913235127\n",
      "0.35857906076010915\n",
      "0.35857906076010915\n",
      "0.22396738968520757\n",
      "0.22396738968520757\n",
      "0.006464321368900738\n",
      "0.006464321368900738\n",
      "0.149369572512967\n",
      "0.149369572512967\n",
      "0.5696015763990958\n",
      "0.5696015763990958\n",
      "0.4552274375937047\n",
      "0.4552274375937047\n",
      "-0.026832981383788757\n",
      "-0.026832981383788757\n",
      "0.2728486706524452\n",
      "0.2728486706524452\n",
      "0.23461429267738088\n",
      "0.23461429267738088\n",
      "0.15887382301823966\n",
      "0.15887382301823966\n",
      "-0.004562850264789808\n",
      "-0.004562850264789808\n",
      "0.2430241669814584\n",
      "0.2430241669814584\n",
      "0.011323708151519507\n",
      "0.011323708151519507\n",
      "0.17613987390275443\n",
      "0.17613987390275443\n",
      "0.39922123688495315\n",
      "0.39922123688495315\n",
      "0.2715180659125324\n",
      "0.2715180659125324\n",
      "-0.09709327150681468\n",
      "-0.09709327150681468\n",
      "-0.00503440121520482\n",
      "-0.00503440121520482\n",
      "0.24552636632694835\n",
      "0.24552636632694835\n",
      "0.305626472741084\n",
      "0.305626472741084\n",
      "0.5672728237066211\n",
      "0.5672728237066211\n",
      "0.1579057192719796\n",
      "0.1579057192719796\n",
      "-0.4131571347413457\n",
      "-0.4131571347413457\n",
      "0.17839793006945265\n",
      "0.17839793006945265\n",
      "-0.11634408335255153\n",
      "-0.11634408335255153\n",
      "-0.12187757959990753\n",
      "-0.12187757959990753\n",
      "-0.2750476781818182\n",
      "-0.2750476781818182\n",
      "0.06924682167146934\n",
      "0.06924682167146934\n",
      "0.4903261708139731\n",
      "0.4903261708139731\n",
      "0.37491572851053273\n",
      "0.37491572851053273\n",
      "0.04700879332887231\n",
      "0.04700879332887231\n",
      "0.1912122086738774\n",
      "0.1912122086738774\n",
      "0.3755349287420987\n",
      "0.3755349287420987\n",
      "0.21444315338388442\n",
      "0.21444315338388442\n",
      "0.48734702029541455\n",
      "0.48734702029541455\n",
      "0.1272703375816892\n",
      "0.1272703375816892\n",
      "0.5331802188084824\n",
      "0.5331802188084824\n",
      "0.16476138343630775\n",
      "0.16476138343630775\n",
      "0.048922370030330176\n",
      "0.048922370030330176\n",
      "0.005860007408677093\n",
      "0.005860007408677093\n",
      "0.06615950742297405\n",
      "0.06615950742297405\n",
      "-0.13296462171926715\n",
      "-0.13296462171926715\n",
      "0.16738036224125297\n",
      "0.16738036224125297\n"
     ]
    }
   ],
   "source": [
    "model = BackPropagatingPerceptron()\n",
    "for epoch in range(0, 1):\n",
    "    if epoch % 10 == 0:\n",
    "        print(model.forward_pass(X_train, y_train))\n",
    "    model.forward_pass(X_train, y_train)\n",
    "    model.backwards_pass(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abfc4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self):\n",
    "        self.layer_out = Layer(n_nodes = 1)\n",
    "    \n",
    "    def forward_pass(self, X, y):\n",
    "        output = self.layer_out.forward_pass(X)\n",
    "        cost_out = []\n",
    "        for i in range(X.shape[0]):\n",
    "            cost = half_mse(output[0][i], y[i])\n",
    "            cost_out.append(cost)\n",
    "        return sum(cost_out)\n",
    "    \n",
    "    def backwards_pass(self, X, y):\n",
    "        cost_delta = []\n",
    "        for i in range(X.shape[0]):\n",
    "            cost_delta.append(-(y[i] - self.layer_out.nodes[0].outputs[i]))\n",
    "        z_delta_next = [[cost_delta]] # [prev_node_1[curr_node1_deltas[instances], curr_node2_delta[instance]], prev_node_2...]\n",
    "            \n",
    "        self.layer_out.backwards_pass(X, z_delta_next)\n",
    "            \n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_nodes):\n",
    "        self.nodes = []\n",
    "        for i in range(n_nodes):\n",
    "            self.nodes.append(Node(2))\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        outputs = []\n",
    "        for i in range(len(self.nodes)):\n",
    "            outputs.append(self.nodes[i].forward_pass(X))\n",
    "        return outputs\n",
    "    \n",
    "    def backwards_pass(self, X, z_delta_next):\n",
    "        for i in range(len(self.nodes)):\n",
    "            self.nodes[i].backwards_pass(X, z_delta_next[i])\n",
    "        \n",
    "class Node:\n",
    "    def __init__(self, n_inputs):\n",
    "        self.outputs = []\n",
    "        self.weights = []\n",
    "        self.bias = 0.5 #random.random()\n",
    "        self.l_rate = 0.5\n",
    "         \n",
    "        for i in range(n_inputs):\n",
    "            self.weights.append(0.5)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        self.outputs = []\n",
    "        out = []\n",
    "        for i in range(X.shape[0]):\n",
    "            z_sum = 0\n",
    "            for j in range(len(self.weights)):\n",
    "                z_sum += self.weights[j] * X[i, j]\n",
    "            z_sum += self.bias\n",
    "            self.outputs.append(sigmoid(z_sum))\n",
    "        return self.outputs\n",
    "    \n",
    "    def backwards_pass(self, X, z_delta_next):\n",
    "        w_delta_matrix = [[] for i in range(len(self.weights))]\n",
    "        b_delta_array = []\n",
    "        for i in range(0, X.shape[0]):\n",
    "            z_delta = self.outputs[i]*(1-self.outputs[i])\n",
    "            for j in range(len(self.weights)):\n",
    "                part_w_delta = z_delta * X[i, j]\n",
    "                full_w_delta = 0\n",
    "                for k in range(len(z_delta_next)):\n",
    "                    full_w_delta += z_delta_next[k][i] * part_w_delta\n",
    "                w_delta_matrix[j].append(full_w_delta)\n",
    "            b_delta_array.append(self.outputs[i]*(1-self.outputs[i]))\n",
    "        \n",
    "        for i in range(len(w_delta_matrix)):\n",
    "            self.weights[i] = self.weights[i] - (self.l_rate * (sum(w_delta_matrix[i]) / len(w_delta_matrix[i])))\n",
    "        self.bias = self.bias - (self.l_rate * (sum(b_delta_array) / len(b_delta_array)))\n",
    "        \n",
    "        \n",
    "# return z_delta * the weights\n",
    "\n",
    "# once I sort the input into backwards_pass() and output of backward_pass()... it should work with any number of\n",
    "# layers and nodes?\n",
    "\n",
    "# the thing that's making this confusing is having to keep track of the instances in the main backprop code...\n",
    "# could that loop be moved elsewhere somehow?\n",
    "\n",
    "# I need to add to a z_delta_next for each node in prevous layer during backprop\n",
    "# For each node in previous layer, each node should add its z_delta multiplied by the weight for the prev layer node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8016c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.767620345732574\n",
      "[0.4935362573447928, 0.500291033619962]\n",
      "14.36593479983957\n",
      "[0.486373223513595, 0.49973699664759574]\n",
      "13.060944043929076\n",
      "[0.4786688852921059, 0.4984386952645876]\n",
      "11.873124706457787\n",
      "[0.4706009599599929, 0.4965271309159595]\n",
      "10.822733726401399\n",
      "[0.46236167783518695, 0.494160817688519]\n",
      "9.92852274863209\n",
      "[0.45415082881161406, 0.49152034791928123]\n",
      "9.206232230907798\n",
      "[0.44616733103269224, 0.48880020870215235]\n",
      "8.667049257624866\n",
      "[0.4385999380280136, 0.4861983902981928]\n",
      "8.316284084179221\n",
      "[0.4316180355335624, 0.4839048869504642]\n",
      "8.152537232400759\n",
      "[0.425363663530186, 0.4820905861333835]\n",
      "8.16756603640367\n",
      "[0.41994582546726467, 0.48089810256031723]\n",
      "8.346921587301667\n",
      "[0.41543779175176576, 0.4804357728869881]\n",
      "8.671255263470098\n",
      "[0.4118775594675138, 0.48077537806912807]\n",
      "9.118049880269641\n",
      "[0.4092710676243011, 0.4819534189961815]\n",
      "9.663464142833107\n",
      "[0.4075973593371657, 0.4839751732978589]\n",
      "10.284004287882345\n",
      "[0.40681472315090333, 0.48682045509770455]\n",
      "10.957828771966268\n",
      "[0.4068669243324884, 0.4904499994766333]\n",
      "11.665606515806475\n",
      "[0.4076888679809827, 0.4948116102090842]\n",
      "12.390947337199915\n",
      "[0.4092113147355411, 0.4998455172049335]\n",
      "13.120484497582755\n",
      "[0.41136451674997165, 0.5054886847771519]\n",
      "13.843712609762248\n",
      "[0.41408081722170653, 0.5116780358046019]\n",
      "14.55267970613332\n",
      "[0.4172963564866582, 0.5183526956600568]\n",
      "15.241613041678141\n",
      "[0.4209520664549763, 0.5254554255262047]\n",
      "15.906534711907847\n",
      "[0.42499413384976165, 0.5329334295170819]\n",
      "16.544901747089064\n",
      "[0.4293740899881723, 0.5407387052989797]\n",
      "17.155288714065644\n",
      "[0.43404865406078935, 0.5488280798552873]\n",
      "17.737119387181107\n",
      "[0.4389794260409969, 0.5571630409483418]\n",
      "18.290446959716512\n",
      "[0.44413249845474345, 0.5657094462152567]\n",
      "18.8157784210815\n",
      "[0.4494780346240138, 0.5744371680050853]\n",
      "19.313937051131507\n",
      "[0.4549898445936273, 0.583319713467084]\n",
      "19.785956636110008\n",
      "[0.46064497803973975, 0.5923338455533415]\n",
      "20.233001393338796\n",
      "[0.4664233451261521, 0.6014592206699297]\n",
      "20.65630631547318\n",
      "[0.4723073706472388, 0.6106780518214111]\n",
      "21.057133476146866\n",
      "[0.47828168313533664, 0.6199748014645383]\n",
      "21.43674064829642\n",
      "[0.4843328383345637, 0.6293359052847212]\n",
      "21.796359311952877\n",
      "[0.49044907511612196, 0.6387495262459044]\n",
      "22.13717974678554\n",
      "[0.49662010121588546, 0.6482053371800459]\n",
      "22.460341414844585\n",
      "[0.5028369058902331, 0.6576943296167101]\n",
      "22.766927250164862\n",
      "[0.5090915965566017, 0.6672086463237814]\n",
      "23.057960797846157\n",
      "[0.5153772566070325, 0.6767414350110643]\n",
      "23.33440540037386\n",
      "[0.5216878217872692, 0.6862867207544306]\n",
      "23.59716482674957\n",
      "[0.5280179727763389, 0.6958392948727237]\n",
      "23.84708489218252\n",
      "[0.53436304185424, 0.7053946181962621]\n",
      "24.084955732440026\n",
      "[0.5407189317917327, 0.7149487368814481]\n",
      "24.311514485436515\n",
      "[0.547082045326938, 0.7244982091367549]\n",
      "24.527448199603086\n",
      "[0.5534492238038997, 0.7340400414233473]\n",
      "24.73339683902958\n",
      "[0.5598176937367888, 0.7435716328747793]\n",
      "24.929956293201524\n",
      "[0.5661850202301785, 0.7530907268430974]\n",
      "25.1176813273834\n",
      "[0.5725490663319394, 0.7625953686232636]\n",
      "25.297088430643143\n",
      "[0.5789079575225085, 0.7720838685349666]\n",
      "25.468658533947643\n",
      "[0.5852600506544673, 0.781554769651968]\n",
      "25.63283958204024\n",
      "[0.5916039067514731, 0.7910068195656863]\n",
      "25.7900489509699\n",
      "[0.597938267157476, 0.8004389456533463]\n",
      "25.94067570896097\n",
      "[0.6042620325975445, 0.809850233393264]\n",
      "26.08508272238765\n",
      "[0.6105742447720626, 0.8192399073321326]\n",
      "26.22360861139332\n",
      "[0.6168740701579232, 0.8286073143628289]\n",
      "26.35656956151707\n",
      "[0.623160785734848, 0.8379519090174421]\n",
      "26.48426099880636\n",
      "[0.629433766393146, 0.8472732405199627]\n",
      "26.606959136505534\n",
      "[0.6356924738120044, 0.8565709413772598]\n",
      "26.724922401650524\n",
      "[0.6419364466255651, 0.8658447173164069]\n",
      "26.838392749886594\n",
      "[0.648165291718238, 0.8750943384017555]\n",
      "26.947596876633217\n",
      "[0.6543786765115319, 0.8843196311869919]\n",
      "27.05274733240544\n",
      "[0.6605763221226135, 0.8935204717762419]\n",
      "27.154043549718562\n",
      "[0.6667579972902684, 0.902696779684542]\n",
      "27.25167278856902\n",
      "[0.6729235129772833, 0.9118485124020297]\n",
      "27.345811007036502\n",
      "[0.6790727175698003, 0.9209756605783538]\n",
      "27.436623663097137\n",
      "[0.6852054926041747, 0.9300782437543134]\n",
      "27.52426645329135\n",
      "[0.6913217489605104, 0.9391563065768449]\n",
      "27.60888599345767\n",
      "[0.6974214234695458, 0.9482099154413852]\n",
      "27.69062044633354\n",
      "[0.70350447588608, 0.9572391555125033]\n",
      "27.769600100434836\n",
      "[0.7095708861877872, 0.9662441280796692]\n",
      "27.845947904261987\n",
      "[0.7156206521632071, 0.9752249482102315]\n",
      "27.919779959543696\n",
      "[0.7216537872569965, 0.9841817426662084]\n",
      "27.991205976912507\n",
      "[0.7276703186442834, 0.993114648055459]\n",
      "28.060329697120594\n",
      "[0.7336702855092518, 1.0020238091912619]\n",
      "28.127249280634622\n",
      "[0.739653737505954, 1.0109093776373559]\n",
      "28.192057668206278\n",
      "[0.7456207333818724, 1.019771510418151]\n",
      "28.254842914790224\n",
      "[0.7515713397469603, 1.0286103688761459]\n",
      "28.31568849897588\n",
      "[0.7575056299728341, 1.03742611766063]\n",
      "28.374673609914122\n",
      "[0.7634236832085, 1.046218923833547]\n",
      "28.431873413547358\n",
      "[0.7693255835005023, 1.0549889560799763]\n",
      "28.487359299796896\n",
      "[0.7752114190067088, 1.0637363840120828]\n",
      "28.541199112219566\n",
      "[0.78108128129412, 1.072461377556615]\n",
      "28.593457361515217\n",
      "[0.7869352647121262, 1.0811641064171174]\n",
      "28.644195424151338\n",
      "[0.7927734658335517, 1.0898447396029798]\n",
      "28.69347172726044\n",
      "[0.7985959829566396, 1.098503445018299]\n",
      "28.74134192087138\n",
      "[0.8044029156618483, 1.1071403891042784]\n",
      "28.787859038444562\n",
      "[0.8101943644179728, 1.1157557365295572]\n",
      "28.833073646601093\n",
      "[0.8159704302326709, 1.1243496499234573]\n",
      "28.877033984861537\n",
      "[0.8217312143429804, 1.1329222896476543]\n",
      "28.919786096143074\n",
      "[0.8274768179418626, 1.141473813602255]\n",
      "28.961373948701556\n",
      "[0.8332073419372116, 1.1500043770626756]\n",
      "29.001839550150212\n",
      "[0.8389228867401233, 1.158514132544084]\n",
      "29.041223054134655\n",
      "[0.8446235520795407, 1.1670032296905077]\n",
      "29.079562860197193\n",
      "[0.850309436840677, 1.1754718151859955]\n",
      "29.116895707322126\n",
      "[0.8559806389248746, 1.1839200326854902]\n",
      "29.15325676161261\n",
      "[0.8616372551287861, 1.192348022763304]\n",
      "29.188679698516278\n",
      "[0.8672793810409689, 1.2007559228773004]\n",
      "29.22319677998263\n",
      "[0.8729071109541723, 1.2091438673470707]\n",
      "29.256838926906294\n",
      "[0.8785205377917563, 1.2175119873445708]\n",
      "29.289635787182544\n",
      "[0.8841197530468359, 1.225860410895827]\n",
      "29.32161579967673\n",
      "[0.8897048467328725, 1.2341892628924631]\n",
      "29.352806254386135\n",
      "[0.8952759073445605, 1.2424986651119176]\n",
      "29.383233349051842\n",
      "[0.9008330218279607, 1.2507887362453358]\n",
      "29.41292224245898\n",
      "[0.9063762755589331, 1.2590595919322143]\n",
      "29.44189710464592\n",
      "[0.9119057523290086, 1.2673113448009714]\n",
      "29.47018116422623\n",
      "[0.9174215343379195, 1.2755441045146914]\n",
      "29.497796753013667\n",
      "[0.9229237021920798, 1.2837579778213655]\n",
      "29.52476534812472\n",
      "[0.9284123349083723, 1.2919530686080185]\n",
      "29.551107611722358\n",
      "[0.9338875099226596, 1.3001294779581682]\n",
      "29.57684342855126\n",
      "[0.9393493031024858, 1.3082873042121177]\n",
      "29.601991941406304\n",
      "[0.944797788763489, 1.3164266430296279]\n",
      "29.626571584663008\n",
      "[0.9502330396890842, 1.3245475874545645]\n",
      "29.650600115993207\n",
      "[0.9556551271530196, 1.3326502279811505]\n",
      "29.6740946463771\n",
      "[0.9610641209444422, 1.3407346526214896]\n",
      "29.69707166851808\n",
      "[0.9664600893951453, 1.3488009469740623]\n",
      "29.71954708375753\n",
      "[0.9718430994086968, 1.3568491942929237]\n",
      "29.741536227580696\n",
      "[0.9772132164911767, 1.3648794755573572]\n",
      "29.763053893799082\n",
      "[0.982570504783275, 1.3728918695417645]\n",
      "29.784114357488537\n",
      "[0.9879150270935282, 1.3808864528855955]\n",
      "29.804731396756857\n",
      "[0.9932468449324858, 1.3888633001631372]\n",
      "29.8249183134101\n",
      "[0.9985660185476254, 1.3968224839530035]\n",
      "29.844687952582337\n",
      "[1.003872606958845, 1.404764074907182]\n",
      "29.86405272138882\n",
      "[1.0091666679943818, 1.412688141819509]\n",
      "29.883024606659387\n",
      "[1.014448258327018, 1.4205947516934592]\n",
      "29.901615191804574\n",
      "[1.0197174335104493, 1.4284839698091463]\n",
      "29.919835672864103\n",
      "[1.0249742480157018, 1.4363558597894452]\n",
      "29.937696873783395\n",
      "[1.0302187552674964, 1.4442104836651555]\n",
      "29.955209260962366\n",
      "[1.035451007680467, 1.4520479019391335]\n",
      "29.972382957116476\n",
      "[1.040671056695151, 1.4598681736493342]\n",
      "29.989227754487754\n",
      "[1.045878952813676, 1.467671356430705]\n",
      "30.00575312744275\n",
      "[1.0510747456350784, 1.4754575065758877]\n",
      "30.021968244489443\n",
      "[1.0562584838901907, 1.483226679094687]\n",
      "30.037881979745674\n",
      "[1.0614302154760473, 1.49097892777227]\n",
      "30.053502923888082\n",
      "[1.0665899874897609, 1.4987143052260703]\n",
      "30.068839394609437\n",
      "[1.0717378462618263, 1.5064328629613721]\n",
      "30.083899446610296\n",
      "[1.0768738373888183, 1.5141346514255556]\n",
      "30.098690881150002\n",
      "[1.0819980057654468, 1.5218197200609875]\n",
      "30.113221255179408\n",
      "[1.0871103956159478, 1.5294881173565482]\n",
      "30.12749789007759\n",
      "[1.09221105052478, 1.5371398908977862]\n",
      "30.141527880012546\n",
      "[1.097300013466611, 1.5447750874156976]\n",
      "30.1553180999456\n",
      "[1.102377326835576, 1.5523937528341274]\n",
      "30.16887521329703\n",
      "[1.107443032473793, 1.5599959323157966]\n",
      "30.18220567929085\n",
      "[1.1124971716991245, 1.5675816703069574]\n",
      "30.19531575999366\n",
      "[1.1175397853321796, 1.5751510105806839]\n",
      "30.208211527063888\n",
      "[1.1225709137225452, 1.5827039962788059]\n",
      "30.220898868225245\n",
      "[1.1275905967742483, 1.5902406699524974]\n",
      "30.233383493477692\n",
      "[1.1325988739704422, 1.59776107360153]\n",
      "30.245670941059238\n",
      "[1.137595784397321, 1.605265248712207]\n",
      "30.257766583169943\n",
      "[1.1425813667672593, 1.612753236293991]\n",
      "30.269675631470086\n",
      "[1.1475556594411842, 1.6202250769148419]\n",
      "30.28140314236314\n",
      "[1.152518700450182, 1.6276808107352845]\n",
      "30.292954022073225\n",
      "[1.1574705275163444, 1.635120477541221]\n",
      "30.30433303152734\n",
      "[1.1624111780728639, 1.6425441167755095]\n",
      "30.315544791051146\n",
      "[1.1673406892833824, 1.6499517675683297]\n",
      "30.32659378488664\n",
      "[1.1722590980606058, 1.6573434687663537]\n",
      "30.337484365540472\n",
      "[1.1771664410841907, 1.664719258960746]\n",
      "30.34822075797003\n",
      "[1.1820627548179155, 1.6720791765140135]\n",
      "30.35880706361481\n",
      "[1.1869480755261475, 1.6794232595857286]\n",
      "30.36924726428017\n",
      "[1.1918224392896153, 1.6867515461571478]\n",
      "30.379545225879927\n",
      "[1.1966858820205017, 1.69406407405475]\n",
      "30.389704702043495\n",
      "[1.2015384394768673, 1.701360880972716]\n",
      "30.399729337594405\n",
      "[1.2063801472764186, 1.7086420044943775]\n",
      "30.40962267190502\n",
      "[1.2112110409096362, 1.7159074821126528]\n",
      "30.419388142133027\n",
      "[1.216031155752273, 1.7231573512495]\n",
      "30.429029086344908\n",
      "[1.2208405270772402, 1.730391649274408]\n",
      "30.43854874653064\n",
      "[1.2256391900658934, 1.7376104135219503]\n",
      "30.447950271515055\n",
      "[1.2304271798187327, 1.744813681308427]\n",
      "30.457236719768936\n",
      "[1.235204531365534, 1.7520014899476168]\n",
      "30.466411062125445\n",
      "[1.2399712796749232, 1.759173876765667]\n",
      "30.475476184404293\n",
      "[1.2447274596634101, 1.7663308791151409]\n",
      "30.484434889948375\n",
      "[1.2494731062038964, 1.7734725343882496]\n",
      "30.493289902075997\n",
      "[1.2542082541336714, 1.780598880029292]\n",
      "30.502043866452357\n",
      "[1.2589329382619123, 1.7877099535463243]\n",
      "30.5106993533829\n",
      "[1.2636471933767022, 1.7948057925220842]\n",
      "30.519258860031893\n",
      "[1.2683510542515803, 1.8018864346241925]\n",
      "30.527724812569737\n",
      "[1.273044555651642, 1.8089519176146556]\n",
      "30.53609956825067\n",
      "[1.277727732339198, 1.8160022793586883]\n",
      "30.54438541742394\n",
      "[1.2824006190790118, 1.8230375578328848]\n",
      "30.55258458548185\n",
      "[1.2870632506431274, 1.830057791132754]\n",
      "30.560699234745105\n",
      "[1.2917156618153014, 1.8370630174796452]\n",
      "30.568731466290092\n",
      "[1.2963578873950534, 1.8440532752270822]\n",
      "30.576683321718264\n",
      "[1.3009899622013499, 1.8510286028665301]\n",
      "30.58455678487079\n",
      "[1.3056119210759327, 1.8579890390326126]\n",
      "30.592353783490633\n",
      "[1.310223798886307, 1.8649346225078007]\n",
      "30.60007619083294\n",
      "[1.3148256305284018, 1.8718653922265944]\n",
      "30.607725827226545\n",
      "[1.3194174509289147, 1.8787813872792145]\n",
      "30.615304461587844\n",
      "[1.3239992950473551, 1.885682646914826]\n",
      "30.622813812889024\n",
      "[1.3285711978777974, 1.8925692105443093]\n",
      "30.63025555158176\n",
      "[1.3331331944503557, 1.8994411177425996]\n",
      "30.637631300978423\n",
      "[1.3376853198323937, 1.9062984082506118]\n",
      "30.644942638591925\n",
      "[1.3422276091294791, 1.9131411219767684]\n",
      "30.652191097435647\n",
      "[1.3467600974860967, 1.9199692989981467]\n",
      "30.659378167285197\n",
      "[1.3512828200861275, 1.9267829795612637]\n",
      "30.66650529590243\n",
      "[1.3557958121531097, 1.9335822040825141]\n",
      "30.67357389022399\n",
      "[1.3602991089502867, 1.9403670131482775]\n",
      "30.68058531751473\n",
      "[1.3647927457804574, 1.947137447514709]\n",
      "30.687540906487705\n",
      "[1.3692767579856344, 1.9538935481072313]\n",
      "30.69444194839119\n",
      "[1.3737511809465244, 1.9606353560197407]\n",
      "30.70128969806487\n",
      "[1.378216050081836, 1.9673629125135408]\n",
      "30.7080853749649\n",
      "[1.3826714008474268, 1.9740762590160208]\n",
      "30.714830164159782\n",
      "[1.3871172687352997, 1.9807754371190882]\n",
      "30.721525217297433\n",
      "[1.3915536892724525, 1.9874604885773723]\n",
      "30.72817165354494\n",
      "[1.395980698019595, 1.9941314553062088]\n",
      "30.734770560500753\n",
      "[1.4003983305697383, 2.0007883793794194]\n",
      "30.7413229950819\n",
      "[1.4048066225466647, 2.0074313030268978]\n",
      "30.74782998438504\n",
      "[1.4092056096032866, 2.0140602686320133]\n",
      "30.754292526523656\n",
      "[1.4135953274199022, 2.020675318728845]\n",
      "30.76071159144136\n",
      "[1.4179758117023538, 2.027276495999254]\n",
      "30.767088121702354\n",
      "[1.4223470981800963, 2.033863843269809]\n",
      "30.77342303325951\n",
      "[1.4267092226041838, 2.0404374035085695]\n",
      "30.779717216200932\n",
      "[1.4310622207451784, 2.046997219821743]\n",
      "30.785971535475458\n",
      "[1.4354061283909902, 2.0535433354502213]\n",
      "30.792186831598052\n",
      "[1.4397409813446513, 2.0600757937660026]\n",
      "30.79836392133492\n",
      "[1.4440668154220333, 2.066594638268518]\n",
      "30.804503598370435\n",
      "[1.4483836664495104, 2.07309991258086]\n",
      "30.810606633954364\n",
      "[1.452691570261576, 2.079591660445926]\n",
      "30.81667377753193\n",
      "[1.4569905626984163, 2.086069925722488]\n",
      "30.822705757355653\n",
      "[1.4612806796034477, 2.0925347523811877]\n",
      "30.828703281080866\n",
      "[1.4655619568208187, 2.098986184500471]\n",
      "30.834667036344086\n",
      "[1.4698344301928874, 2.105424266262469]\n",
      "30.840597691325623\n",
      "[1.4740981355576723, 2.111849041948828]\n",
      "30.84649589529655\n",
      "[1.478353108746285, 2.118260555936494]\n",
      "30.85236227915074\n",
      "[1.4825993855803452, 2.1246588526934698]\n",
      "30.85819745592148\n",
      "[1.4868370018693875, 2.1310439767745306]\n",
      "30.86400202128478\n",
      "[1.491065993408256, 2.1374159728169237]\n",
      "30.86977655404791\n",
      "[1.4952863959744955, 2.1437748855360432]\n",
      "30.875521616624845\n",
      "[1.4994982453257424, 2.1501207597210934]\n",
      "30.88123775549865\n",
      "[1.503701577197115, 2.1564536402307413]\n",
      "30.886925501670746\n",
      "[1.5078964272986095, 2.162773571988765]\n",
      "30.892585371098235\n",
      "[1.5120828313125039, 2.169080599979701]\n",
      "30.89821786511861\n",
      "[1.5162608248907694, 2.175374769244498]\n",
      "30.90382347086317\n",
      "[1.5204304436524971, 2.181656124876174]\n",
      "30.90940266165905\n",
      "[1.5245917231813382, 2.18792471201549]\n",
      "30.914955897419667\n",
      "[1.5287446990229612, 2.1941805758466355]\n",
      "30.9204836250251\n",
      "[1.5328894066825283, 2.2004237615929356]\n",
      "30.92598627869132\n",
      "[1.5370258816221938, 2.206654314512578]\n",
      "30.93146428032968\n",
      "[1.5411541592586249, 2.2128722798943667]\n",
      "30.936918039896323\n",
      "[1.545274274960547, 2.219077703053503]\n",
      "30.942347955731854\n",
      "[1.5493862640463165, 2.2252706293273956]\n",
      "30.947754414891936\n",
      "[1.5534901617815204, 2.231451104071509]\n",
      "30.953137793468233\n",
      "[1.557586003376607, 2.237619172655242]\n",
      "30.95849845690122\n",
      "[1.5616738239845445, 2.2437748804578472]\n",
      "30.963836760283684\n",
      "[1.5657536586985155, 2.2499182728643903]\n",
      "30.969153048656114\n",
      "[1.569825542549641, 2.2560493952617504]\n",
      "30.974447657294114\n",
      "[1.5738895105047404, 2.2621682930346663]\n",
      "30.979720911987453\n",
      "[1.5779455974641263, 2.2682750115618258]\n",
      "30.98497312931173\n",
      "[1.5819938382594354, 2.274369596212004]\n",
      "30.990204616892264\n",
      "[1.5860342676514956, 2.28045209234025]\n",
      "30.99541567366121\n",
      "[1.5900669203282314, 2.2865225452841234]\n",
      "31.000606590106653\n",
      "[1.594091830902607, 2.2925810003599816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.005777648515668\n",
      "[1.598109033910608, 2.29862750285932]\n",
      "31.010929123209948\n",
      "[1.6021185638092625, 2.3046620980451658]\n",
      "31.01606128077564\n",
      "[1.6061204549747021, 2.3106848311485253]\n",
      "31.021174380286062\n",
      "[1.6101147417002628, 2.316695747364887]\n",
      "31.026268673518565\n",
      "[1.6141014581946256, 2.3226948918507806]\n",
      "31.03134440516549\n",
      "[1.6180806385799988, 2.328682309720392]\n",
      "31.036401813038992\n",
      "[1.6220523168903411, 2.334658046042237]\n",
      "31.041441128270332\n",
      "[1.6260165270696245, 2.340622145835889]\n",
      "31.04646257550345\n",
      "[1.6299733029701398, 2.3465746540687697]\n",
      "31.05146637308348\n",
      "[1.633922678350842, 2.3525156156529943]\n",
      "31.056452733239627\n",
      "[1.6378646868757387, 2.358445075442276]\n",
      "31.06142186226293\n",
      "[1.6417993621123173, 2.3643630782288922]\n",
      "31.066373960679524\n",
      "[1.6457267375300155, 2.3702696687407054]\n",
      "31.071309223418552\n",
      "[1.649646846498732, 2.3761648916382465]\n",
      "31.076227839975523\n",
      "[1.6535597222873777, 2.3820487915118562]\n",
      "31.08112999457131\n",
      "[1.6574653980624687, 2.387921412878885]\n",
      "31.08601586630639\n",
      "[1.661363906886759, 2.393782800180952]\n",
      "31.090885629310765\n",
      "[1.6652552817179138, 2.3996329977812656]\n",
      "31.095739452890083\n",
      "[1.6691395554072237, 2.4054720499619986]\n",
      "31.100577501667043\n",
      "[1.6730167606983573, 2.411300000921725]\n",
      "31.105399935719284\n",
      "[1.6768869302261542, 2.4171168947729145]\n",
      "31.110206910713202\n",
      "[1.6807500965154578, 2.4229227755394835]\n",
      "31.114998578034083\n",
      "[1.6846062919799853, 2.4287176871544065]\n",
      "31.119775084912206\n",
      "[1.688455548921238, 2.4345016734573823]\n",
      "31.124536574546195\n",
      "[1.692297899527449, 2.4402747781925593]\n",
      "31.12928318622179\n",
      "[1.6961333758725674, 2.4460370450063156]\n",
      "31.134015055428264\n",
      "[1.699962009915283, 2.4517885174450966]\n",
      "31.138732313971012\n",
      "[1.7037838334980842, 2.457529238953308]\n",
      "31.143435090080715\n",
      "[1.7075988783463543, 2.4632592528712625]\n",
      "31.14812350852024\n",
      "[1.7114071760675045, 2.468978602433184]\n",
      "31.15279769068763\n",
      "[1.7152087581501405, 2.4746873307652635]\n",
      "31.157457754716596\n",
      "[1.7190036559632655, 2.4803854808837684]\n",
      "31.162103815574124\n",
      "[1.7227919007555172, 2.486073095693208]\n",
      "31.166735985155302\n",
      "[1.726573523654439, 2.491750217984547]\n",
      "31.17135437237528\n",
      "[1.7303485556657854, 2.497416890433475]\n",
      "31.175959083258668\n",
      "[1.734117027672859, 2.5030731555987225]\n",
      "31.180550221026554\n",
      "[1.7378789704358812, 2.5087190559204338]\n",
      "31.185127886180865\n",
      "[1.7416344145913951, 2.5143546337185825]\n",
      "31.18969217658621\n",
      "[1.745383390651699, 2.5199799311914424]\n",
      "31.194243187549553\n",
      "[1.7491259290043109, 2.5255949904141026]\n",
      "31.19878101189779\n",
      "[1.752862059911465, 2.531199853337034]\n",
      "31.203305740052357\n",
      "[1.7565918135096363, 2.5367945617847005]\n",
      "31.207817460102653\n",
      "[1.7603152198090948, 2.542379157454218]\n",
      "31.212316257876562\n",
      "[1.76403230869349, 2.547953681914059]\n",
      "31.216802217009384\n",
      "[1.7677431099194618, 2.553518176602802]\n",
      "31.221275419010617\n",
      "[1.7714476531162813, 2.559072682827926]\n",
      "31.22573594332882\n",
      "[1.7751459677855164, 2.5646172417646484]\n",
      "31.230183867414592\n",
      "[1.778838083300726, 2.5701518944548063]\n",
      "31.23461926678172\n",
      "[1.78252402890718, 2.575676681805779]\n"
     ]
    }
   ],
   "source": [
    "model = MultiLayerPerceptron()\n",
    "\n",
    "for epoch in range(0, 300):\n",
    "    print(model.forward_pass(X_train, y_train))\n",
    "    model.backwards_pass(X_train, y_train)\n",
    "    print(model.layer_out.nodes[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "819f565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        self.layer_h1 = Layer(n_nodes = 3, n_inputs = 2)\n",
    "        self.layer_o = Layer(n_nodes = 1, n_inputs = 1)\n",
    "        \n",
    "        self.costs = []\n",
    "    \n",
    "    def forward_pass(self, x, y):\n",
    "        output = self.layer_h1.forward_pass(x)\n",
    "        output = self.layer_o.forward_pass(output)\n",
    "        cost = half_mse(output, y)\n",
    "        self.costs.append(cost)\n",
    "    \n",
    "    def get_cost(self):\n",
    "        total_cost = sum(self.costs)\n",
    "        self.costs = []\n",
    "        return total_cost\n",
    "    \n",
    "    def backwards_pass(self, x, y):\n",
    "        out_output_grads = [[-(y - self.layer_o.prev_outputs[0])]]\n",
    "        h1_output_grads = self.layer_o.backwards_pass(self.layer_h1.prev_outputs, out_output_grads)\n",
    "        _ = self.layer_h1.backwards_pass(x, h1_output_grads)\n",
    "        \n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_nodes, n_inputs):\n",
    "        self.nodes = []\n",
    "        self.prev_outputs = []\n",
    "        for i in range(n_nodes):\n",
    "            self.nodes.append(Node(n_inputs))\n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "        self.prev_outputs = []\n",
    "        for node in self.nodes:\n",
    "            self.prev_outputs.append(node.forward_pass(inputs))\n",
    "        return self.prev_outputs\n",
    "    \n",
    "    def backwards_pass(self, inputs, output_grad_matrix):\n",
    "        input_grad_matrix = [[] for i in range(len(inputs))]\n",
    "        for i in range(len(self.nodes)):\n",
    "            input_grads = self.nodes[i].backwards_pass(inputs, output_grad_matrix[i])\n",
    "            for j in range(len(input_grads)):\n",
    "                input_grad_matrix[j].append(input_grads[j]) # this could be a transpose operation\n",
    "        return input_grad_matrix\n",
    "              \n",
    "    \n",
    "class Node:\n",
    "    def __init__(self, n_inputs):\n",
    "        self.prev_output = None\n",
    "        self.l_rate = 0.0005\n",
    "        self.bias = 0.5\n",
    "        self.weights = []\n",
    "        for _ in range(n_inputs):\n",
    "            self.weights.append(0.5)\n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "            z_sum = 0\n",
    "            for i in range(len(self.weights)):\n",
    "                z_sum += self.weights[i] * inputs[i]\n",
    "            z_sum += self.bias\n",
    "            output = sigmoid(z_sum)\n",
    "            self.prev_output = output\n",
    "            return output\n",
    "        \n",
    "    def backwards_pass(self, inputs, output_grads):\n",
    "        input_grads = []\n",
    "        z_grad = self.prev_output*(1-self.prev_output)\n",
    "        for i in range(len(self.weights)):\n",
    "            part_input_grad = z_grad * self.weights[i]\n",
    "            full_input_grad = 0\n",
    "            part_weight_grad = z_grad * inputs[i]\n",
    "            full_weight_grad = 0\n",
    "            for j in range(len(output_grads)):\n",
    "                full_input_grad += output_grads[j] * part_input_grad\n",
    "                full_weight_grad += output_grads[j] * part_weight_grad\n",
    "            input_grads.append(full_input_grad)   \n",
    "            self.weights[i] = self.weights[i] - (self.l_rate * full_weight_grad)\n",
    "        bias_grad = self.prev_output*(1-self.prev_output) #?\n",
    "        self.bias = self.bias - (self.l_rate * bias_grad)\n",
    "        return input_grads     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a782170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.30618334]\n",
      "[21.44562776]\n",
      "[20.59394883]\n",
      "[19.75388269]\n",
      "[18.92823876]\n",
      "[18.11987278]\n",
      "[17.33165687]\n",
      "[16.56644694]\n",
      "[15.82704802]\n",
      "[15.11617853]\n",
      "[14.43643388]\n",
      "[13.79025085]\n",
      "[13.17987324]\n",
      "[12.6073201]\n",
      "[12.07435734]\n",
      "[11.58247357]\n",
      "[11.13286087]\n",
      "[10.72640114]\n",
      "[10.36365824]\n",
      "[10.04487618]\n",
      "[9.76998325]\n",
      "[9.5386018]\n",
      "[9.35006328]\n",
      "[9.20342783]\n",
      "[9.09750777]\n",
      "[9.0308941]\n",
      "[9.0019852]\n",
      "[9.00901684]\n",
      "[9.05009269]\n",
      "[9.12321458]\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "for i in range(30):\n",
    "    for j in range(331):\n",
    "        model.forward_pass(X_train[j, :], y_train[j])\n",
    "        model.backwards_pass(X_train[j, :], y_train[j])\n",
    "    print(model.get_cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "368a3dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4df9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
